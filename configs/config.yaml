# Hyperparameter configs

config: configs/config.yaml
cuda: True
cuda_devices: "1"

output_dir: pretrained_model/ontonotes_chinese14
experiment: tars_cross_lingual_pretraing

runs: 1
#set_seed: False
final_test: True

language_model: xlm-roberta-large
corpus: chinese_14
save_model: True
train_batch_size: 16
eval_batch_size: 16
lr: 5e-6
epochs: 10

k: 2
sampling_mode: strict
reuse_decoder_weights: False
reuse_corpus_for_weights: conll

num_negatives: one