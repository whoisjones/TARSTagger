# Hyperparameter configs

config: configs/config.yaml
cuda: True
cuda_devices: "1"

output_dir: pretrained_models/conll_xlmr_1neg
experiment: tars_pretrain

runs: 1
#set_seed: False
final_test: True

language_model: xlm-roberta-large
corpus: conll
save_model: True
train_batch_size: 32
eval_batch_size: 32
lr: 5e-6
epochs: 10

k: 5
sampling_mode: soft
reuse_decoder_weights: False
reuse_corpus_for_weights: conll

num_negatives: one
